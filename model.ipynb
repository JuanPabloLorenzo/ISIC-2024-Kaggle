{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T20:42:19.402478Z","iopub.status.busy":"2024-07-26T20:42:19.402114Z","iopub.status.idle":"2024-07-26T20:42:33.666779Z","shell.execute_reply":"2024-07-26T20:42:33.665815Z","shell.execute_reply.started":"2024-07-26T20:42:19.402447Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import h5py\n","import io\n","from PIL import Image\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from operator import itemgetter\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n","import os\n","import xgboost\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T20:42:58.961831Z","iopub.status.busy":"2024-07-26T20:42:58.960674Z","iopub.status.idle":"2024-07-26T20:42:58.969769Z","shell.execute_reply":"2024-07-26T20:42:58.968305Z","shell.execute_reply.started":"2024-07-26T20:42:58.961789Z"},"trusted":true},"outputs":[],"source":["def is_kaggle():\n","    return os.path.exists('/kaggle')\n","\n","class Config:\n","    BASE_PATH = '/kaggle/input/isic-2024-challenge/' if is_kaggle() else 'isic-2024-challenge/'\n","    TRAIN_IMAGE_PATH = 'train-image.hdf5'\n","    TRAIN_METADATA_PATH = 'train-metadata.csv'\n","    TEST_IMAGE_PATH = 'test-image.hdf5'\n","    TEST_METADATA_PATH = 'test-metadata.csv'\n","    \n","    # Data processing\n","    IMAGE_SIZE = (120, 120)\n","    VALIDATION_SPLIT = 0.15\n","    RANDOM_STATE = 42\n","    \n","    BATCH_SIZE = 32\n","    \n","    class MetadataModule:\n","        ACTIVATION = 'relu'\n","        KERNEL_INITIALIZER = 'he_normal'\n","        \n","    class ImageModule:\n","        ACTIVATION = 'relu'\n","        KERNEL_INITIALIZER = 'he_normal'"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocesamiento"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T20:43:00.904974Z","iopub.status.busy":"2024-07-26T20:43:00.904260Z","iopub.status.idle":"2024-07-26T20:43:06.942299Z","shell.execute_reply":"2024-07-26T20:43:06.941367Z","shell.execute_reply.started":"2024-07-26T20:43:00.904940Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/bw/_7s8wxw93cngpt5f7bg5s3hm0000gn/T/ipykernel_23871/2340496625.py:4: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n","  train_metadata = pd.read_csv(Config.BASE_PATH + Config.TRAIN_METADATA_PATH)\n"]}],"source":["train_hdf5 = h5py.File(Config.BASE_PATH + Config.TRAIN_IMAGE_PATH, 'r')\n","test_hdf5 = h5py.File(Config.BASE_PATH + Config.TEST_IMAGE_PATH, 'r')\n","\n","train_metadata = pd.read_csv(Config.BASE_PATH + Config.TRAIN_METADATA_PATH)\n","test_metadata = pd.read_csv(Config.BASE_PATH + Config.TEST_METADATA_PATH)\n","\n","train_fnames = train_metadata[\"isic_id\"].tolist()\n","test_fnames = test_metadata[\"isic_id\"].tolist()\n","\n","train_target = train_metadata[\"target\"]\n","\n","split = StratifiedShuffleSplit(n_splits=1, test_size=Config.VALIDATION_SPLIT, random_state=Config.RANDOM_STATE)\n","for train_index, val_index in split.split(train_metadata, train_target):\n","    val_fnames = itemgetter(*val_index)(train_fnames)\n","    train_fnames = itemgetter(*train_index)(train_fnames)\n","    X_metadata_train, X_metadata_val = train_metadata.iloc[train_index], train_metadata.iloc[val_index]\n","    y_train, y_val = train_target.iloc[train_index], train_target.iloc[val_index]"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T20:43:12.051636Z","iopub.status.busy":"2024-07-26T20:43:12.051255Z","iopub.status.idle":"2024-07-26T20:43:14.414852Z","shell.execute_reply":"2024-07-26T20:43:14.413866Z","shell.execute_reply.started":"2024-07-26T20:43:12.051607Z"},"trusted":true},"outputs":[],"source":["only_train_cols = [\"target\", \"lesion_id\", \"iddx_full\", \"iddx_1\", \"iddx_2\", \"iddx_3\", \"iddx_4\", \"iddx_5\", \"mel_mitotic_index\", \"mel_thick_mm\", \"tbp_lv_dnn_lesion_confidence\"]\n","unuseful_cols = [\"image_type\", \"patient_id\"]\n","removable_cols = only_train_cols + unuseful_cols + [\"isic_id\"]\n","\n","numeric_features = train_metadata.select_dtypes(include=['float64', 'int64']).columns.difference(removable_cols)\n","cat_features = train_metadata.select_dtypes(include=['object']).columns.difference(removable_cols)\n","\n","numeric_pipeline = Pipeline([\n","    ('impute', SimpleImputer(strategy='mean')),\n","    ('scale', StandardScaler())\n","])\n","\n","cat_pipeline = Pipeline([\n","    ('impute', SimpleImputer(strategy='most_frequent')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n","])\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_pipeline, numeric_features),\n","        ('cat', cat_pipeline, cat_features)\n","    ])\n","\n","metadata_preprocessing_pipeline = Pipeline([\n","    ('preprocessor', preprocessor)\n","])\n","\n","X_train_metadata_preprocessed = metadata_preprocessing_pipeline.fit_transform(X_metadata_train)\n","X_val_metadata_preprocessed = metadata_preprocessing_pipeline.transform(X_metadata_val)\n","X_test_metadata_preprocessed = metadata_preprocessing_pipeline.transform(test_metadata)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T22:44:08.739878Z","iopub.status.busy":"2024-07-26T22:44:08.739446Z","iopub.status.idle":"2024-07-26T22:44:09.631510Z","shell.execute_reply":"2024-07-26T22:44:09.630459Z","shell.execute_reply.started":"2024-07-26T22:44:08.739850Z"},"trusted":true},"outputs":[],"source":["def create_dataset(fnames, metadata_preprocessed, targets, hdf5):\n","    target_ds = tf.data.Dataset.from_tensor_slices(targets)\n","    \n","    def load_image(id):\n","        image = Image.open(io.BytesIO(np.array(hdf5[id.numpy()])))\n","        image = np.array(image.resize(Config.IMAGE_SIZE)).reshape(120, 120, 3)\n","        return image\n","\n","    # It doesn't work without this in Kaggle\n","    def set_shapes(image):\n","        image.set_shape([120, 120, 3])\n","        return image\n","\n","    # Create a dataset for images\n","    image_ds = tf.data.Dataset.from_tensor_slices(tf.constant(fnames))\n","    image_ds = image_ds.map(lambda x: tf.py_function(load_image, [x], tf.float32))\n","    image_ds = image_ds.map(set_shapes)\n","    solo_image_ds = tf.data.Dataset.zip((image_ds, target_ds)).batch(Config.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","\n","    # Create a dataset for metadata\n","    metadata_ds = tf.data.Dataset.from_tensor_slices(metadata_preprocessed)\n","    solo_metadata_ds = tf.data.Dataset.zip((metadata_ds, target_ds)).batch(Config.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","\n","    # Combine the datasets\n","    combined_ds = tf.data.Dataset.zip(((image_ds, metadata_ds), target_ds))\n","    combined_ds = combined_ds.shuffle(1000)\n","    combined_ds = combined_ds.batch(Config.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","\n","    return solo_image_ds, solo_metadata_ds, combined_ds\n","\n","train_solo_image_ds, train_solo_metadata_ds, train_ds = create_dataset(train_fnames, X_train_metadata_preprocessed, y_train, train_hdf5)\n","val_solo_image_ds, val_solo_metadata_ds, val_ds = create_dataset(val_fnames, X_val_metadata_preprocessed, y_val, train_hdf5)\n","\n","# TEST\n","test_solo_image_ds, test_solo_metadata_ds, test_ds = create_dataset(test_fnames, X_test_metadata_preprocessed, np.zeros(len(test_fnames)), test_hdf5)"]},{"cell_type":"markdown","metadata":{},"source":["# Auxiliary functions and classes"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T22:44:09.634076Z","iopub.status.busy":"2024-07-26T22:44:09.633661Z","iopub.status.idle":"2024-07-26T22:44:09.644307Z","shell.execute_reply":"2024-07-26T22:44:09.643126Z","shell.execute_reply.started":"2024-07-26T22:44:09.634039Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc, roc_auc_score\n","\n","def pauc_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n","    v_gt = abs(y_true - 1)\n","    v_pred = 1.0 - y_pred\n","    min_tpr = 0.80\n","    max_fpr = 1 - min_tpr\n","    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n","    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n","    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n","    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n","    \n","    return partial_auc\n","\n","class PAUCCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, validation_data, batch_size):\n","        super(PAUCCallback, self).__init__()\n","        self.validation_data = validation_data\n","        self.batch_size = batch_size\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        # Get predictions for validation data\n","        val_pred = self.model.predict(self.validation_data, verbose=0)\n","        \n","        # Extract true labels from validation data\n","        y_val = np.concatenate([y for x, y in self.validation_data], axis=0)\n","        \n","        # Calculate pAUC score\n","        pauc = pauc_score(y_val, val_pred)\n","        \n","        # Optionally, you can add the pAUC score to the logs\n","        logs['val_pauc'] = pauc"]},{"cell_type":"markdown","metadata":{},"source":["# Metadata module"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T22:44:10.458427Z","iopub.status.busy":"2024-07-26T22:44:10.457539Z","iopub.status.idle":"2024-07-26T22:44:10.698902Z","shell.execute_reply":"2024-07-26T22:44:10.697727Z","shell.execute_reply.started":"2024-07-26T22:44:10.458393Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Shuffle 1/15\n","pAUC = 0.1292\n","pAUC = 0.1359\n","\n","\n","Shuffle 2/15\n","pAUC = 0.1408\n","pAUC = 0.1323\n","\n","\n","Shuffle 3/15\n","pAUC = 0.1342\n","pAUC = 0.1431\n","\n","\n","Shuffle 4/15\n","pAUC = 0.1301\n","pAUC = 0.1516\n","\n","\n","Shuffle 5/15\n","pAUC = 0.1424\n","pAUC = 0.1226\n","\n","\n","Shuffle 6/15\n","pAUC = 0.1531\n","pAUC = 0.1391\n","\n","\n","Shuffle 7/15\n","pAUC = 0.1406\n","pAUC = 0.1449\n","\n","\n","Shuffle 8/15\n","pAUC = 0.1391\n","pAUC = 0.1378\n","\n","\n","Shuffle 9/15\n","pAUC = 0.1380\n","pAUC = 0.1479\n","\n","\n","Shuffle 10/15\n","pAUC = 0.1362\n","pAUC = 0.1425\n","\n","\n","Shuffle 11/15\n","pAUC = 0.1441\n","pAUC = 0.1388\n","\n","\n","Shuffle 12/15\n","pAUC = 0.1359\n","pAUC = 0.1524\n","\n","\n","Shuffle 13/15\n","pAUC = 0.1420\n","pAUC = 0.1408\n","\n","\n","Shuffle 14/15\n","pAUC = 0.1305\n","pAUC = 0.1369\n","\n","\n","Shuffle 15/15\n","pAUC = 0.1521\n","pAUC = 0.1136\n","\n","\n"]}],"source":["from sklearn.model_selection import KFold\n","\n","metadata_input_shape = next(iter(train_solo_metadata_ds.take(1)))[0].shape[1:]\n","\n","shuffles = 15\n","splits = 2\n","models = []\n","scores = []\n","\n","for i in range(shuffles):\n","    print(f\"Shuffle {i+1}/{shuffles}\")\n","    split = KFold(n_splits=splits, shuffle=True)\n","    for train_index, val_index in split.split(X_metadata_train, y_train):\n","        X_metadata_train_split, X_metadata_val_split = X_metadata_train.iloc[train_index], X_metadata_train.iloc[val_index]\n","        y_train_split, y_val_split = y_train.iloc[train_index], y_train.iloc[val_index]\n","        \n","        X_train_metadata_preprocessed_split = metadata_preprocessing_pipeline.fit_transform(X_metadata_train_split)\n","        X_val_metadata_preprocessed_split = metadata_preprocessing_pipeline.transform(X_metadata_val_split)\n","        \n","        xgb_model = xgboost.XGBClassifier(n_estimators=300, n_jobs=-1, max_depth=2)\n","        xgb_model.fit(X_train_metadata_preprocessed_split, y_train_split)\n","\n","        pred = xgb_model.predict_proba(X_val_metadata_preprocessed_split)\n","        score = pauc_score(y_val_split, pred[:, 1])\n","        print(f\"pAUC = {score:.4f}\")\n","        \n","        scores.append(score)\n","        models.append(xgb_model)\n","    \n","    print(\"\\n\")"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Making predictions on the validation set:\n","0.1742281790236611\n"]}],"source":["# Get the indices of the sorted scores\n","sorted_indices = [i for i, _ in sorted(enumerate(scores), key=lambda x: x[1], reverse=True)]\n","\n","best_models = [models[i] for i in sorted_indices]\n","\n","print(\"Making predictions on the validation set:\")\n","\n","y_preds = []\n","for i, model in enumerate(best_models, 1):\n","    # Make predictions on the validation set\n","    y_pred = model.predict_proba(X_val_metadata_preprocessed)[:, 1]\n","    \n","    y_preds.append(y_pred)\n","\n","y_preds = np.array(y_preds)\n","\n","n = 20\n","final_pred = np.mean(y_preds[:n], axis=0)\n","print(pauc_score(y_val, final_pred))"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.16116318001071656\n"]}],"source":["# xgb_model = xgboost.XGBClassifier(n_estimators=100, n_jobs=-1, max_depth=3)\n","# xgb_model.fit(X_train_metadata_preprocessed, y_train)\n","\n","# pred = xgb_model.predict_proba(X_val_metadata_preprocessed)\n","# print(pauc_score(y_val, pred[:, 1]))"]},{"cell_type":"markdown","metadata":{},"source":["# Image Module"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T22:44:14.837260Z","iopub.status.busy":"2024-07-26T22:44:14.836864Z","iopub.status.idle":"2024-07-26T22:44:14.922152Z","shell.execute_reply":"2024-07-26T22:44:14.921116Z","shell.execute_reply.started":"2024-07-26T22:44:14.837229Z"},"trusted":true},"outputs":[],"source":["# image_input_shape = next(iter(train_image_ds.take(1))).shape\n","\n","# image_model = Sequential([\n","#     Conv2D(32, 3, 2, activation=Config.MetadataModule.ACTIVATION, kernel_initializer=Config.MetadataModule.KERNEL_INITIALIZER, input_shape=image_input_shape),\n","#     Conv2D(16, 3, 2, activation=Config.MetadataModule.ACTIVATION, kernel_initializer=Config.MetadataModule.KERNEL_INITIALIZER),\n","#     MaxPooling2D(2, 2),\n","#     Flatten(),\n","#     Dense(64, activation=Config.MetadataModule.ACTIVATION, kernel_initializer=Config.MetadataModule.KERNEL_INITIALIZER),\n","#     Dense(1, activation='sigmoid')\n","# ])\n","\n","# # Compile the model\n","# optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","# image_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# # Callbacks\n","# pauc_callback = PAUCCallback(val_solo_image_ds.take(100), Config.BATCH_SIZE)\n","\n","# # Display model summary\n","# image_model.summary()\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T22:33:01.527468Z","iopub.status.busy":"2024-07-26T22:33:01.527071Z","iopub.status.idle":"2024-07-26T22:35:10.121988Z","shell.execute_reply":"2024-07-26T22:35:10.120705Z","shell.execute_reply.started":"2024-07-26T22:33:01.527436Z"},"trusted":true},"outputs":[],"source":["# image_model.fit(train_solo_image_ds.take(500), validation_data=val_solo_image_ds.take(100), epochs=1, callbacks=[pauc_callback])"]},{"cell_type":"markdown","metadata":{},"source":["# Combined Modules"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T22:44:24.243613Z","iopub.status.busy":"2024-07-26T22:44:24.243245Z","iopub.status.idle":"2024-07-26T22:44:24.279723Z","shell.execute_reply":"2024-07-26T22:44:24.278513Z","shell.execute_reply.started":"2024-07-26T22:44:24.243584Z"},"trusted":true},"outputs":[],"source":["# image_input = tf.keras.Input(shape=image_input_shape)\n","# metadata_input = tf.keras.Input(shape=metadata_input_shape)\n","\n","# # Clone and freeze image model layers\n","# # x_image = image_input\n","# # for layer in image_model.layers[:-1]:  # Exclude the last layer\n","# #     x_image = layer(x_image)\n","# #     layer.trainable = False\n","\n","# # Clone and freeze metadata model layers\n","# x_metadata = metadata_input\n","# for layer in metadata_model.layers[:-1]:  # Exclude the last layer\n","#     x_metadata = layer(x_metadata)\n","#     layer.trainable = False\n","\n","# # Concatenate the outputs of both models\n","# # combined = tf.keras.layers.Concatenate()([x_image, x_metadata])\n","# x = tf.keras.layers.Dense(16, activation=Config.MetadataModule.ACTIVATION, kernel_initializer=Config.MetadataModule.KERNEL_INITIALIZER)(x_metadata)\n","# x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n","\n","# # Define inputs\n","# input = [image_input, metadata_input]\n","\n","# combined_model = tf.keras.Model(inputs=input, outputs=x)\n","\n","# pauc_callback = PAUCCallback(val_ds.take(100), Config.BATCH_SIZE)\n","\n","# # Compile the model\n","# optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n","# combined_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T22:44:24.535464Z","iopub.status.busy":"2024-07-26T22:44:24.534765Z","iopub.status.idle":"2024-07-26T22:44:28.237944Z","shell.execute_reply":"2024-07-26T22:44:28.236546Z","shell.execute_reply.started":"2024-07-26T22:44:24.535429Z"},"trusted":true},"outputs":[],"source":["# combined_model.fit(train_ds.take(500), validation_data=val_ds.take(100), epochs=1, callbacks=[pauc_callback])\n","\n","# # Unfreeze layers in the image model\n","# for layer in combined_model.layers:\n","#     if isinstance(layer, tf.keras.Model) and layer.name == image_model.name:\n","#         for sub_layer in layer.layers:\n","#             sub_layer.trainable = True\n","\n","# # Unfreeze layers in the metadata model\n","# for layer in combined_model.layers:\n","#     if isinstance(layer, tf.keras.Model) and layer.name == metadata_model.name:\n","#         for sub_layer in layer.layers:\n","#             sub_layer.trainable = True\n","\n","# # Recompile the model with a lower learning rate for fine-tuning\n","# optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n","# combined_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# print(\"Layers unfrozen and model recompiled for fine-tuning.\")\n","\n","# combined_model.fit(train_ds.take(500), validation_data=val_ds.take(100), epochs=1, callbacks=[pauc_callback])"]},{"cell_type":"markdown","metadata":{},"source":["# Submission"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-07-26T22:52:11.781374Z","iopub.status.busy":"2024-07-26T22:52:11.780578Z","iopub.status.idle":"2024-07-26T22:52:12.089014Z","shell.execute_reply":"2024-07-26T22:52:12.087900Z","shell.execute_reply.started":"2024-07-26T22:52:11.781339Z"},"trusted":true},"outputs":[],"source":["submission = pd.read_csv(Config.BASE_PATH + 'sample_submission.csv')\n","\n","# zero_labels = tf.data.Dataset.from_tensor_slices(tf.zeros(len(test_ds)))\n","# test_ds_with_zeros = tf.data.Dataset.zip((test_ds, zero_labels))\n","# zero_labels = tf.data.Dataset.from_tensor_slices(tf.zeros(len(test_metadata_ds)))\n","# test_ds_with_zeros = tf.data.Dataset.zip((test_metadata_ds, zero_labels)).batch(Config.BATCH_SIZE)\n","\n","# submission[\"target\"] = combined_model.predict(test_ds_with_zeros)\n","# submission[\"target\"] = metadata_model.predict(test_ds_with_zeros)\n","# submission[\"target\"] = xgb_model.predict_proba(X_test_metadata_preprocessed)[:, 1]\n","y_preds = []\n","for i, model in enumerate(best_models, 1):\n","    # Make predictions on the validation set\n","    y_pred = model.predict_proba(X_test_metadata_preprocessed)[:, 1]\n","    y_preds.append(y_pred)\n","\n","y_preds = np.array(y_preds)\n","\n","final_pred = np.mean(y_preds, axis=0)\n","submission[\"target\"] = final_pred\n","submission.to_csv('submission.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":9094797,"sourceId":63056,"sourceType":"competition"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
