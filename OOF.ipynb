{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.13 (you have 1.4.12). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import io\n",
    "from PIL import Image\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import os\n",
    "import albumentations as A\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "\n",
    "\n",
    "def is_kaggle():\n",
    "    return os.path.exists('/kaggle')\n",
    "\n",
    "class Config:\n",
    "    BASE_PATH = '/kaggle/input/isic-2024-challenge/' if is_kaggle() else 'isic-2024-challenge/'\n",
    "    TRAIN_IMAGE_PATH = 'train-image.hdf5'\n",
    "    TRAIN_METADATA_PATH = 'train-metadata.csv'\n",
    "    TEST_IMAGE_PATH = 'test-image.hdf5'\n",
    "    TEST_METADATA_PATH = 'test-metadata.csv'\n",
    "    \n",
    "    # Data processing\n",
    "    IMAGE_SIZE = (120, 120)\n",
    "    RANDOM_STATE = 42\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "np.random.seed(Config.RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    eps = 1e-6\n",
    "    df[\"lesion_size_ratio\"] = np.minimum(df[\"tbp_lv_minorAxisMM\"] / (df[\"clin_size_long_diam_mm\"] + eps), 1.015)\n",
    "    df[\"lesion_shape_index\"] = np.minimum(df[\"tbp_lv_areaMM2\"] / (df[\"tbp_lv_perimeterMM\"] ** 2 + eps), 0.093)\n",
    "    df[\"hue_contrast\"] = (df[\"tbp_lv_H\"] - df[\"tbp_lv_Hext\"]).abs()\n",
    "    df[\"luminance_contrast\"] = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs()\n",
    "    df[\"lesion_color_difference\"] = np.sqrt(df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2)\n",
    "    df[\"border_complexity\"] = df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_symm_2axis\"]\n",
    "    df[\"color_uniformity\"] = np.log1p(np.minimum(df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_radial_color_std_max\"], 1000))\n",
    "    df[\"3d_position_distance\"] = np.sqrt(df[\"tbp_lv_x\"] ** 2 + df[\"tbp_lv_y\"] ** 2 + df[\"tbp_lv_z\"] ** 2) \n",
    "    df[\"perimeter_to_area_ratio\"] = np.minimum(df[\"tbp_lv_perimeterMM\"] / (df[\"tbp_lv_areaMM2\"] + eps), 6.02)\n",
    "    df[\"lesion_visibility_score\"] = df[\"tbp_lv_deltaLBnorm\"] + df[\"tbp_lv_norm_color\"]\n",
    "    df[\"combined_anatomical_site\"] = df[\"anatom_site_general\"] + \"_\" + df[\"tbp_lv_location\"]\n",
    "    df[\"symmetry_border_consistency\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"]\n",
    "    df[\"color_consistency\"] = np.minimum(df[\"tbp_lv_stdL\"] / (df[\"tbp_lv_Lext\"] + eps), 0.305)\n",
    "    \n",
    "    df[\"size_age_interaction\"] = df[\"clin_size_long_diam_mm\"] * df[\"age_approx\"]\n",
    "    df[\"hue_color_std_interaction\"] = df[\"tbp_lv_H\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "    df[\"lesion_severity_index\"] = (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_eccentricity\"]) / 3\n",
    "    df[\"shape_complexity_index\"] = df[\"border_complexity\"] + df[\"lesion_shape_index\"]\n",
    "    df[\"color_contrast_index\"] = df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"] + df[\"tbp_lv_deltaLBnorm\"]\n",
    "    df[\"log_lesion_area\"] = np.log(df[\"tbp_lv_areaMM2\"] + 1)\n",
    "    df[\"normalized_lesion_size\"] = np.minimum(df[\"clin_size_long_diam_mm\"] / (df[\"age_approx\"] + eps), 1.59)\n",
    "    df[\"mean_hue_difference\"] = (df[\"tbp_lv_H\"] + df[\"tbp_lv_Hext\"]) / 2\n",
    "    df[\"std_dev_contrast\"] = np.sqrt((df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2) / 3)\n",
    "    df[\"color_shape_composite_index\"] = (df[\"tbp_lv_color_std_mean\"] + df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_symm_2axis\"]) / 3\n",
    "    df[\"3d_lesion_orientation\"] = np.arctan2(df[\"tbp_lv_y\"], df[\"tbp_lv_x\"])\n",
    "    df[\"overall_color_difference\"] = (df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"]) / 3\n",
    "    df[\"symmetry_perimeter_interaction\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_perimeterMM\"]\n",
    "    df[\"comprehensive_lesion_index\"] = (df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_eccentricity\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_symm_2axis\"]) / 4\n",
    "\n",
    "    # Taken from: https://www.kaggle.com/code/dschettler8845/isic-detect-skin-cancer-let-s-learn-together\n",
    "    df[\"color_variance_ratio\"] = np.minimum(df[\"tbp_lv_color_std_mean\"] / (df[\"tbp_lv_stdLExt\"] + eps), 7.94)\n",
    "    df[\"border_color_interaction\"] = df[\"tbp_lv_norm_border\"] * df[\"tbp_lv_norm_color\"]\n",
    "    df[\"size_color_contrast_ratio\"] = np.minimum(df[\"clin_size_long_diam_mm\"] / (df[\"tbp_lv_deltaLBnorm\"] + eps), 5.08)\n",
    "    df[\"age_normalized_nevi_confidence\"] = np.minimum(df[\"tbp_lv_nevi_confidence\"] / (df[\"age_approx\"] + eps), 9.42)\n",
    "    df[\"color_asymmetry_index\"] = df[\"tbp_lv_radial_color_std_max\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "    df[\"3d_volume_approximation\"] = df[\"tbp_lv_areaMM2\"] * np.sqrt(df[\"tbp_lv_x\"]**2 + df[\"tbp_lv_y\"]**2 + df[\"tbp_lv_z\"]**2)\n",
    "    df[\"color_range\"] = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs() + (df[\"tbp_lv_A\"] - df[\"tbp_lv_Aext\"]).abs() + (df[\"tbp_lv_B\"] - df[\"tbp_lv_Bext\"]).abs()\n",
    "    df[\"shape_color_consistency\"] = df[\"tbp_lv_eccentricity\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "    df[\"border_length_ratio\"] = np.minimum(df[\"tbp_lv_perimeterMM\"] / (2 * np.pi * np.sqrt(df[\"tbp_lv_areaMM2\"] / np.pi) + eps), 2.64)\n",
    "    df[\"age_size_symmetry_index\"] = df[\"age_approx\"] * df[\"clin_size_long_diam_mm\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "    # Until here.\n",
    "    \n",
    "    new_num_cols = [\n",
    "        \"lesion_size_ratio\", \"lesion_shape_index\", \"hue_contrast\",\n",
    "        \"luminance_contrast\", \"lesion_color_difference\", \"border_complexity\",\n",
    "        \"color_uniformity\", \"3d_position_distance\", \"perimeter_to_area_ratio\",\n",
    "        \"lesion_visibility_score\", \"symmetry_border_consistency\", \"color_consistency\",\n",
    "\n",
    "        \"size_age_interaction\", \"hue_color_std_interaction\", \"lesion_severity_index\", \n",
    "        \"shape_complexity_index\", \"color_contrast_index\", \"log_lesion_area\",\n",
    "        \"normalized_lesion_size\", \"mean_hue_difference\", \"std_dev_contrast\",\n",
    "        \"color_shape_composite_index\", \"3d_lesion_orientation\", \"overall_color_difference\",\n",
    "        \"symmetry_perimeter_interaction\", \"comprehensive_lesion_index\",\n",
    "        \n",
    "        \"color_variance_ratio\", \"border_color_interaction\", \"size_color_contrast_ratio\",\n",
    "        \"age_normalized_nevi_confidence\", \"color_asymmetry_index\", \"3d_volume_approximation\",\n",
    "        \"color_range\", \"shape_color_consistency\", \"border_length_ratio\", \"age_size_symmetry_index\",\n",
    "    ]\n",
    "    new_cat_cols = [\"combined_anatomical_site\"]\n",
    "    return df, new_num_cols, new_cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bw/_7s8wxw93cngpt5f7bg5s3hm0000gn/T/ipykernel_91375/2284648895.py:4: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_metadata = pd.read_csv(Config.BASE_PATH + Config.TRAIN_METADATA_PATH)[:5000]\n"
     ]
    }
   ],
   "source": [
    "train_hdf5 = h5py.File(Config.BASE_PATH + Config.TRAIN_IMAGE_PATH, 'r')\n",
    "test_hdf5 = h5py.File(Config.BASE_PATH + Config.TEST_IMAGE_PATH, 'r')\n",
    "\n",
    "train_metadata = pd.read_csv(Config.BASE_PATH + Config.TRAIN_METADATA_PATH)\n",
    "test_metadata = pd.read_csv(Config.BASE_PATH + Config.TEST_METADATA_PATH)\n",
    "\n",
    "# Add features\n",
    "X_metadata_train, new_num_cols, new_cat_cols = feature_engineering(train_metadata)\n",
    "X_metadata_test, _, _ = feature_engineering(test_metadata)\n",
    "\n",
    "fnames = train_metadata[\"isic_id\"]\n",
    "test_fnames = test_metadata[\"isic_id\"]\n",
    "\n",
    "target = train_metadata[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_train_cols = [\"target\", \"lesion_id\", \"iddx_full\", \"iddx_1\", \"iddx_2\", \"iddx_3\", \"iddx_4\", \"iddx_5\", \"mel_mitotic_index\", \"mel_thick_mm\", \"tbp_lv_dnn_lesion_confidence\"]\n",
    "unuseful_cols = [\"image_type\", \"patient_id\"]\n",
    "removable_cols = only_train_cols + unuseful_cols + [\"isic_id\"]\n",
    "\n",
    "numeric_features = X_metadata_train.select_dtypes(include=['float64', 'int64']).columns.difference(removable_cols)\n",
    "cat_features = X_metadata_train.select_dtypes(include=['object']).columns.difference(removable_cols)\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numeric_features),\n",
    "        ('cat', cat_pipeline, cat_features)\n",
    "    ])\n",
    "\n",
    "metadata_preprocessing_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "X_train_metadata_preprocessed = metadata_preprocessing_pipeline.fit_transform(X_metadata_train)\n",
    "X_test_metadata_preprocessed = metadata_preprocessing_pipeline.transform(X_metadata_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 17:57:02.544646: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-08-08 17:57:02.544662: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-08-08 17:57:02.544666: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-08-08 17:57:02.544694: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-08-08 17:57:02.544712: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "def create_image_dataset(fnames, targets, hdf5):\n",
    "    target_ds = tf.data.Dataset.from_tensor_slices(targets)\n",
    "    \n",
    "    def load_image(id):\n",
    "        image = Image.open(io.BytesIO(np.array(hdf5[id.numpy()])))\n",
    "        image = np.array(image.resize(Config.IMAGE_SIZE))\n",
    "        image = (image - image.min()) / (image.max() - image.min())\n",
    "        return image\n",
    "\n",
    "    # It doesn't work without this in Kaggle\n",
    "    def set_shapes(image):\n",
    "        image.set_shape([*Config.IMAGE_SIZE, 3])\n",
    "        return image\n",
    "\n",
    "    # Create a dataset for images\n",
    "    image_ds = tf.data.Dataset.from_tensor_slices(tf.constant(fnames))\n",
    "    image_ds = image_ds.map(lambda x: tf.py_function(load_image, [x], tf.float32))\n",
    "    image_ds = image_ds.map(set_shapes)\n",
    "    solo_image_ds = tf.data.Dataset.zip((image_ds, target_ds))\n",
    "\n",
    "    return solo_image_ds\n",
    "\n",
    "train_solo_image_ds = create_image_dataset(fnames, target, train_hdf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = A.Compose([\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Flip(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, \n",
    "                           scale_limit=0.15, \n",
    "                           rotate_limit=60, \n",
    "                           p=0.5),\n",
    "        A.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, \n",
    "                sat_shift_limit=0.2, \n",
    "                val_shift_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1,0.1), \n",
    "                contrast_limit=(-0.1, 0.1), \n",
    "                p=0.5\n",
    "            ),\n",
    "        ], p=1.)\n",
    "\n",
    "def augment_image(image, label):\n",
    "    def apply_augmentation(img):\n",
    "        img = img.numpy()\n",
    "        img = train_transforms(image=img)['image']\n",
    "        return img\n",
    "\n",
    "    augmented_image = tf.py_function(apply_augmentation, [image], tf.float32)\n",
    "    augmented_image.set_shape(image.shape)\n",
    "    return augmented_image, label\n",
    "\n",
    "# Apply the augmentation to the dataset\n",
    "train_solo_image_augmented_ds = train_solo_image_ds.map(augment_image).batch(Config.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pauc_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    v_gt = abs(y_true - 1)\n",
    "    v_pred = 1.0 - y_pred\n",
    "    min_tpr = 0.80\n",
    "    max_fpr = 1 - min_tpr\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    \n",
    "    return partial_auc\n",
    "\n",
    "class PAUCCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super(PAUCCallback, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Get predictions for validation data\n",
    "        val_pred = self.model.predict(self.validation_data, verbose=0)\n",
    "        \n",
    "        # Extract true labels from validation data\n",
    "        y_val = np.concatenate([y for x, y in self.validation_data], axis=0)\n",
    "        \n",
    "        # Calculate pAUC score\n",
    "        pauc = pauc_score(y_val, val_pred)\n",
    "        \n",
    "        # Optionally, you can add the pAUC score to the logs\n",
    "        logs['val_pauc'] = pauc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientNet = EfficientNetV2B0(weights='imagenet', pooling='avg', include_top=False)\n",
    "\n",
    "# image_input = tf.keras.Input(shape=(*Config.IMAGE_SIZE, 3))\n",
    "# x = efficientNet(image_input)\n",
    "# x = Dense(512, kernel_initializer='he_normal')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(128, kernel_initializer='he_normal')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "# x = Dense(1, activation='sigmoid')(x)\n",
    "# image_model = tf.keras.Model(inputs=image_input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 120, 120, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 120, 120, 32)      128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 120, 120, 32)      9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 120, 120, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 60, 60, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 60, 60, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 60, 60, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 60, 60, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 60, 60, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 60, 60, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " separable_conv2d (Separabl  (None, 30, 30, 128)       8896      \n",
      " eConv2D)                                                        \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 30, 30, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " separable_conv2d_1 (Separa  (None, 30, 30, 128)       17664     \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 30, 30, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 15, 15, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 15, 15, 128)       0         \n",
      "                                                                 \n",
      " separable_conv2d_2 (Separa  (None, 15, 15, 256)       34176     \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 15, 15, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " separable_conv2d_3 (Separa  (None, 15, 15, 256)       68096     \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 15, 15, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 256)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 298593 (1.14 MB)\n",
      "Trainable params: 295905 (1.13 MB)\n",
      "Non-trainable params: 2688 (10.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Activation, Dropout, Input, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, SeparableConv2D\n",
    "\n",
    "image_model = Sequential([\n",
    "    Input(shape=(*Config.IMAGE_SIZE, 3)),\n",
    "    \n",
    "    # Initial convolution block\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    # Second convolution block\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Third convolution block with separable convolutions\n",
    "    SeparableConv2D(128, 3, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    SeparableConv2D(128, 3, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Fourth convolution block with separable convolutions\n",
    "    SeparableConv2D(256, 3, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    SeparableConv2D(256, 3, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    # Dense layers\n",
    "    Dense(256, activation='relu', kernel_initializer='he_normal'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples: 306\n",
      "Positive train samples: 6\n",
      "Negative train samples: 300\n"
     ]
    }
   ],
   "source": [
    "# Create a reduced set of training and validation for the CNN\n",
    "target_reset = target.reset_index(drop=True)\n",
    "\n",
    "# Get the positive instances\n",
    "positive_indices = np.where(target_reset == 1)[0]\n",
    "positive_count = len(positive_indices)\n",
    "\n",
    "negative_ratio = 100\n",
    "negative_indices = np.where(target_reset == 0)[0]\n",
    "negative_count = negative_ratio * positive_count\n",
    "negative_indices = np.random.choice(negative_indices, size=negative_count, replace=False)\n",
    "\n",
    "# Combine positive and selected negative indices\n",
    "selected_indices = np.concatenate([positive_indices, negative_indices])\n",
    "np.random.shuffle(selected_indices)\n",
    "\n",
    "# Create the reduced datasets\n",
    "fnames_reduced = fnames[selected_indices].reset_index(drop=True)\n",
    "target_reduced = target_reset[selected_indices].reset_index(drop=True)\n",
    "\n",
    "print(f\"Total train samples: {len(selected_indices)}\")\n",
    "print(f\"Positive train samples: {positive_count}\")\n",
    "print(f\"Negative train samples: {negative_count}\")\n",
    "\n",
    "def augment_image(image, label):\n",
    "    def apply_augmentation(img):\n",
    "        img = img.numpy()\n",
    "        img = train_transforms(image=img)['image']\n",
    "        return img\n",
    "\n",
    "    augmented_image = tf.py_function(apply_augmentation, [image], tf.float32)\n",
    "    augmented_image.set_shape(image.shape)\n",
    "    return augmented_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 17:57:03.288920: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.6525"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 17:57:04.849564: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-08-08 17:57:05.181893: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 231ms/step - loss: 0.6525 - val_loss: 0.5663 - val_pauc: 0.1000\n",
      "Model for fold 1 saved successfully.\n",
      "2/2 [==============================] - 0s 34ms/step\n",
      "Fold 1 pAUC: 0.09999999999999996\n",
      "Training fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanpablo/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2024-08-08 17:57:05.826835: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.6511"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 17:57:07.193434: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-08-08 17:57:07.429746: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 201ms/step - loss: 0.6511 - val_loss: 0.5593 - val_pauc: 0.1667\n",
      "Model for fold 2 saved successfully.\n",
      "2/2 [==============================] - 0s 34ms/step\n",
      "Fold 2 pAUC: 0.16666666666666663\n",
      "Training fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanpablo/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2024-08-08 17:57:08.058921: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.6534"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 17:57:09.509514: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-08-08 17:57:09.780308: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 214ms/step - loss: 0.6534 - val_loss: 0.5605 - val_pauc: 0.1700\n",
      "Model for fold 3 saved successfully.\n",
      "2/2 [==============================] - 0s 34ms/step\n",
      "Fold 3 pAUC: 0.16999999999999996\n",
      "Training fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanpablo/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2024-08-08 17:57:10.403974: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.6523"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 17:57:11.770712: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-08-08 17:57:12.030949: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 202ms/step - loss: 0.6523 - val_loss: 0.5650 - val_pauc: 0.1967\n",
      "Model for fold 4 saved successfully.\n",
      "2/2 [==============================] - 0s 34ms/step\n",
      "Fold 4 pAUC: 0.1966666666666666\n",
      "Training fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanpablo/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2024-08-08 17:57:12.692059: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.6522WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x3d59a1c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 17:57:14.036473: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x3d59a1c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2024-08-08 17:57:14.437683: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 222ms/step - loss: 0.6522 - val_loss: 0.5670 - val_pauc: 0.0433\n",
      "Model for fold 5 saved successfully.\n",
      "2/2 [==============================] - 0s 33ms/step\n",
      "Fold 5 pAUC: 0.04333333333333334\n",
      "Overall OOF pAUC: 0.018774529435322374\n",
      "Mean of fold scores: 0.13533333333333328\n",
      "OOF predictions saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanpablo/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Define number of folds\n",
    "n_splits = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=Config.RANDOM_STATE)\n",
    "\n",
    "oof_predictions = np.zeros(len(X_train_metadata_preprocessed))\n",
    "fold_scores = []\n",
    "image_models = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(fnames_reduced, target_reduced), 1):\n",
    "    print(f\"Training fold {fold}\")\n",
    "    \n",
    "    train_fnames, val_fnames = fnames_reduced[train_idx], fnames_reduced[val_idx]\n",
    "    y_train, y_val = target_reduced[train_idx], target_reduced[val_idx]\n",
    "    \n",
    "    ds = create_image_dataset(train_fnames, y_train, train_hdf5)\n",
    "    ds = ds.map(augment_image).batch(Config.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    val_ds = create_image_dataset(val_fnames, y_val, train_hdf5)\n",
    "    val_ds = val_ds.batch(Config.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    model = tf.keras.models.clone_model(image_model)\n",
    "    model.set_weights(image_model.get_weights())\n",
    "    \n",
    "    lr = 2e-4\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr) if is_kaggle() else tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "    \n",
    "    history = model.fit(\n",
    "        ds,\n",
    "        epochs=10,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=[PAUCCallback(val_ds)]\n",
    "    )\n",
    "    \n",
    "    image_models.append(model)\n",
    "    \n",
    "    model.save(f'image_models/model_fold_{fold}.h5')\n",
    "    print(f\"Model for fold {fold} saved successfully.\")\n",
    "    \n",
    "    # TODO: Agregar TTA\n",
    "    val_predictions = model.predict(val_ds)\n",
    "    oof_predictions[val_idx] = val_predictions.ravel()\n",
    "    \n",
    "# Calculate overall OOF pauc score\n",
    "oof_score = pauc_score(target, oof_predictions)\n",
    "print(f\"Overall OOF pAUC: {oof_score}\")\n",
    "# Save OOF predictions\n",
    "np.save('oof_predictions.npy', oof_predictions)\n",
    "print(\"OOF predictions saved successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model from fold 1\n",
      "1/1 [==============================] - 0s 120ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 17:57:14.975685: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model from fold 2\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x3d5ea5510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 17:57:15.187644: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x3d5ea5510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 119ms/step\n",
      "Predicting with model from fold 3\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x3d5ea7880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 17:57:15.399460: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x3d5ea7880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step\n",
      "Predicting with model from fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 17:57:15.591133: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 96ms/step\n",
      "Predicting with model from fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 17:57:15.782602: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 97ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "test_ds = create_image_dataset(test_fnames, np.zeros(len(test_fnames)), test_hdf5)\n",
    "test_ds = test_ds.batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_predictions = np.zeros((len(test_fnames), n_splits))\n",
    "\n",
    "for i, model in enumerate(image_models, 1):\n",
    "    print(f\"Predicting with model from fold {i}\")\n",
    "    \n",
    "    fold_predictions = model.predict(test_ds)\n",
    "    test_predictions[:, i-1] = fold_predictions.ravel()\n",
    "\n",
    "# Average predictions across folds\n",
    "test_predictions_mean = np.mean(test_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train_metadata_preprocessed.copy()\n",
    "X_train_final = np.column_stack((X_train_final, oof_predictions))\n",
    "\n",
    "X_test_final = X_test_metadata_preprocessed.copy()\n",
    "X_test_final = np.column_stack((X_test_final, test_predictions_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle 1/2\n",
      "Model saved as lgbm_models/model_shuffle_1_fold_1.joblib\n",
      "pAUC = 0.1998\n",
      "Model saved as lgbm_models/model_shuffle_1_fold_2.joblib\n",
      "pAUC = 0.1998\n",
      "Model saved as lgbm_models/model_shuffle_1_fold_3.joblib\n",
      "pAUC = 0.1934\n",
      "Model saved as lgbm_models/model_shuffle_1_fold_4.joblib\n",
      "pAUC = 0.1876\n",
      "Model saved as lgbm_models/model_shuffle_1_fold_5.joblib\n",
      "pAUC = 0.1964\n",
      "\n",
      "\n",
      "Shuffle 2/2\n",
      "Model saved as lgbm_models/model_shuffle_2_fold_1.joblib\n",
      "pAUC = 0.1998\n",
      "Model saved as lgbm_models/model_shuffle_2_fold_2.joblib\n",
      "pAUC = 0.1998\n",
      "Model saved as lgbm_models/model_shuffle_2_fold_3.joblib\n",
      "pAUC = 0.1986\n",
      "Model saved as lgbm_models/model_shuffle_2_fold_4.joblib\n",
      "pAUC = 0.1980\n",
      "Model saved as lgbm_models/model_shuffle_2_fold_5.joblib\n",
      "pAUC = 0.1595\n",
      "\n",
      "\n",
      "Overall OOF pAUC: 0.18673074355893735\n"
     ]
    }
   ],
   "source": [
    "shuffles = 2\n",
    "splits = 5\n",
    "oof_predictions = np.zeros(len(X_train_final))\n",
    "models = []\n",
    "\n",
    "for i in range(shuffles):\n",
    "    print(f\"Shuffle {i+1}/{shuffles}\")\n",
    "    split = StratifiedKFold(n_splits=splits, shuffle=True)\n",
    "    for j, (train_index, val_index) in enumerate(split.split(X_train_final, target), 1):\n",
    "        X_train, X_val = X_train_final[train_index], X_train_final[val_index]\n",
    "        y_train, y_val = target.iloc[train_index], target.iloc[val_index]\n",
    "        \n",
    "        lgbm_model = lgb.LGBMClassifier(\n",
    "            n_estimators=1500,\n",
    "            max_depth=2,\n",
    "            learning_rate=0.02,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1,\n",
    "        )\n",
    "        \n",
    "        lgbm_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Save the model for this fold\n",
    "        fold_model_filename = f'lgbm_models/model_shuffle_{i+1}_fold_{j}.joblib'\n",
    "        joblib.dump(lgbm_model, fold_model_filename)\n",
    "        print(f\"Model saved as {fold_model_filename}\")\n",
    "\n",
    "        pred = lgbm_model.predict_proba(X_val)\n",
    "        oof_predictions[val_index] += pred[:, 1]\n",
    "        score = pauc_score(y_val, pred[:, 1])\n",
    "        print(f\"pAUC = {score:.4f}\")\n",
    "        \n",
    "        models.append(lgbm_model)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "oof_score = pauc_score(target, oof_predictions)\n",
    "print(f\"Overall OOF pAUC: {oof_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranks = []\n",
    "# for model in models:\n",
    "#     # Get feature importances\n",
    "#     feature_importances = model.feature_importances_\n",
    "\n",
    "#     # Create a dataframe of feature importances\n",
    "#     feature_importance_df = pd.DataFrame({\n",
    "#         'feature': model.feature_name_,\n",
    "#         'importance': feature_importances\n",
    "#     })\n",
    "\n",
    "#     feature = \"Column_138\"\n",
    "#     sorted_importance = feature_importance_df.sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "#     feature_rank = sorted_importance[sorted_importance['feature'] == feature].index[0] + 1\n",
    "#     ranks.append(feature_rank)\n",
    "\n",
    "# print(f\"Average rank: {np.mean(ranks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(Config.BASE_PATH + 'sample_submission.csv')\n",
    "\n",
    "y_preds = []\n",
    "for i, model in enumerate(models, 1):\n",
    "    # Make predictions on the validation set\n",
    "    y_pred = model.predict_proba(X_test_final)[:, 1]\n",
    "    y_preds.append(y_pred)\n",
    "\n",
    "y_preds = np.array(y_preds)\n",
    "\n",
    "final_pred = np.mean(y_preds, axis=0)\n",
    "submission[\"target\"] = final_pred\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
