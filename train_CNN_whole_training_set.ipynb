{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:08:33.526006Z","iopub.status.busy":"2024-08-02T18:08:33.525629Z","iopub.status.idle":"2024-08-02T18:08:37.347298Z","shell.execute_reply":"2024-08-02T18:08:37.346443Z","shell.execute_reply.started":"2024-08-02T18:08:33.525977Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dense, BatchNormalization, Activation, Dropout\n","from tensorflow.keras.applications import EfficientNetV2B0\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import h5py\n","import io\n","from PIL import Image\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from operator import itemgetter\n","import os\n","import albumentations as A\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:08:37.349942Z","iopub.status.busy":"2024-08-02T18:08:37.348996Z","iopub.status.idle":"2024-08-02T18:08:37.356191Z","shell.execute_reply":"2024-08-02T18:08:37.355280Z","shell.execute_reply.started":"2024-08-02T18:08:37.349904Z"},"trusted":true},"outputs":[],"source":["def is_kaggle():\n","    return os.path.exists('/kaggle')\n","\n","class Config:\n","    BASE_PATH = '/kaggle/input/isic-2024-challenge/' if is_kaggle() else 'isic-2024-challenge/'\n","    TRAIN_IMAGE_PATH = 'train-image.hdf5'\n","    TRAIN_METADATA_PATH = 'train-metadata.csv'\n","    TEST_IMAGE_PATH = 'test-image.hdf5'\n","    TEST_METADATA_PATH = 'test-metadata.csv'\n","    \n","    # Data processing\n","    IMAGE_SIZE = (120, 120)\n","    VALIDATION_SPLIT = 0.15\n","    RANDOM_STATE = 42\n","    \n","    BATCH_SIZE = 32"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:08:37.358037Z","iopub.status.busy":"2024-08-02T18:08:37.357640Z","iopub.status.idle":"2024-08-02T18:08:37.380344Z","shell.execute_reply":"2024-08-02T18:08:37.379499Z","shell.execute_reply.started":"2024-08-02T18:08:37.358005Z"},"trusted":true},"outputs":[],"source":["def feature_engineering(df):\n","    eps = 1e-6\n","    df[\"lesion_size_ratio\"] = np.minimum(df[\"tbp_lv_minorAxisMM\"] / (df[\"clin_size_long_diam_mm\"] + eps), 1.015)\n","    df[\"lesion_shape_index\"] = np.minimum(df[\"tbp_lv_areaMM2\"] / (df[\"tbp_lv_perimeterMM\"] ** 2 + eps), 0.093)\n","    df[\"hue_contrast\"] = (df[\"tbp_lv_H\"] - df[\"tbp_lv_Hext\"]).abs()\n","    df[\"luminance_contrast\"] = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs()\n","    df[\"lesion_color_difference\"] = np.sqrt(df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2)\n","    df[\"border_complexity\"] = df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_symm_2axis\"]\n","    df[\"color_uniformity\"] = np.log1p(np.minimum(df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_radial_color_std_max\"], 1000))\n","    df[\"3d_position_distance\"] = np.sqrt(df[\"tbp_lv_x\"] ** 2 + df[\"tbp_lv_y\"] ** 2 + df[\"tbp_lv_z\"] ** 2) \n","    df[\"perimeter_to_area_ratio\"] = np.minimum(df[\"tbp_lv_perimeterMM\"] / (df[\"tbp_lv_areaMM2\"] + eps), 6.02)\n","    df[\"lesion_visibility_score\"] = df[\"tbp_lv_deltaLBnorm\"] + df[\"tbp_lv_norm_color\"]\n","    df[\"combined_anatomical_site\"] = df[\"anatom_site_general\"] + \"_\" + df[\"tbp_lv_location\"]\n","    df[\"symmetry_border_consistency\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"]\n","    df[\"color_consistency\"] = np.minimum(df[\"tbp_lv_stdL\"] / (df[\"tbp_lv_Lext\"] + eps), 0.305)\n","    \n","    df[\"size_age_interaction\"] = df[\"clin_size_long_diam_mm\"] * df[\"age_approx\"]\n","    df[\"hue_color_std_interaction\"] = df[\"tbp_lv_H\"] * df[\"tbp_lv_color_std_mean\"]\n","    df[\"lesion_severity_index\"] = (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_eccentricity\"]) / 3\n","    df[\"shape_complexity_index\"] = df[\"border_complexity\"] + df[\"lesion_shape_index\"]\n","    df[\"color_contrast_index\"] = df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"] + df[\"tbp_lv_deltaLBnorm\"]\n","    df[\"log_lesion_area\"] = np.log(df[\"tbp_lv_areaMM2\"] + 1)\n","    df[\"normalized_lesion_size\"] = np.minimum(df[\"clin_size_long_diam_mm\"] / (df[\"age_approx\"] + eps), 1.59)\n","    df[\"mean_hue_difference\"] = (df[\"tbp_lv_H\"] + df[\"tbp_lv_Hext\"]) / 2\n","    df[\"std_dev_contrast\"] = np.sqrt((df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2) / 3)\n","    df[\"color_shape_composite_index\"] = (df[\"tbp_lv_color_std_mean\"] + df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_symm_2axis\"]) / 3\n","    df[\"3d_lesion_orientation\"] = np.arctan2(df[\"tbp_lv_y\"], df[\"tbp_lv_x\"])\n","    df[\"overall_color_difference\"] = (df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"]) / 3\n","    df[\"symmetry_perimeter_interaction\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_perimeterMM\"]\n","    df[\"comprehensive_lesion_index\"] = (df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_eccentricity\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_symm_2axis\"]) / 4\n","\n","    # Taken from: https://www.kaggle.com/code/dschettler8845/isic-detect-skin-cancer-let-s-learn-together\n","    df[\"color_variance_ratio\"] = np.minimum(df[\"tbp_lv_color_std_mean\"] / (df[\"tbp_lv_stdLExt\"] + eps), 7.94)\n","    df[\"border_color_interaction\"] = df[\"tbp_lv_norm_border\"] * df[\"tbp_lv_norm_color\"]\n","    df[\"size_color_contrast_ratio\"] = np.minimum(df[\"clin_size_long_diam_mm\"] / (df[\"tbp_lv_deltaLBnorm\"] + eps), 5.08)\n","    df[\"age_normalized_nevi_confidence\"] = np.minimum(df[\"tbp_lv_nevi_confidence\"] / (df[\"age_approx\"] + eps), 9.42)\n","    df[\"color_asymmetry_index\"] = df[\"tbp_lv_radial_color_std_max\"] * df[\"tbp_lv_symm_2axis\"]\n","    df[\"3d_volume_approximation\"] = df[\"tbp_lv_areaMM2\"] * np.sqrt(df[\"tbp_lv_x\"]**2 + df[\"tbp_lv_y\"]**2 + df[\"tbp_lv_z\"]**2)\n","    df[\"color_range\"] = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs() + (df[\"tbp_lv_A\"] - df[\"tbp_lv_Aext\"]).abs() + (df[\"tbp_lv_B\"] - df[\"tbp_lv_Bext\"]).abs()\n","    df[\"shape_color_consistency\"] = df[\"tbp_lv_eccentricity\"] * df[\"tbp_lv_color_std_mean\"]\n","    df[\"border_length_ratio\"] = np.minimum(df[\"tbp_lv_perimeterMM\"] / (2 * np.pi * np.sqrt(df[\"tbp_lv_areaMM2\"] / np.pi) + eps), 2.64)\n","    df[\"age_size_symmetry_index\"] = df[\"age_approx\"] * df[\"clin_size_long_diam_mm\"] * df[\"tbp_lv_symm_2axis\"]\n","    # Until here.\n","    \n","    new_num_cols = [\n","        \"lesion_size_ratio\", \"lesion_shape_index\", \"hue_contrast\",\n","        \"luminance_contrast\", \"lesion_color_difference\", \"border_complexity\",\n","        \"color_uniformity\", \"3d_position_distance\", \"perimeter_to_area_ratio\",\n","        \"lesion_visibility_score\", \"symmetry_border_consistency\", \"color_consistency\",\n","\n","        \"size_age_interaction\", \"hue_color_std_interaction\", \"lesion_severity_index\", \n","        \"shape_complexity_index\", \"color_contrast_index\", \"log_lesion_area\",\n","        \"normalized_lesion_size\", \"mean_hue_difference\", \"std_dev_contrast\",\n","        \"color_shape_composite_index\", \"3d_lesion_orientation\", \"overall_color_difference\",\n","        \"symmetry_perimeter_interaction\", \"comprehensive_lesion_index\",\n","        \n","        \"color_variance_ratio\", \"border_color_interaction\", \"size_color_contrast_ratio\",\n","        \"age_normalized_nevi_confidence\", \"color_asymmetry_index\", \"3d_volume_approximation\",\n","        \"color_range\", \"shape_color_consistency\", \"border_length_ratio\", \"age_size_symmetry_index\",\n","    ]\n","    new_cat_cols = [\"combined_anatomical_site\"]\n","    return df, new_num_cols, new_cat_cols"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:08:37.382335Z","iopub.status.busy":"2024-08-02T18:08:37.382064Z","iopub.status.idle":"2024-08-02T18:08:45.808113Z","shell.execute_reply":"2024-08-02T18:08:45.807021Z","shell.execute_reply.started":"2024-08-02T18:08:37.382312Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/bw/_7s8wxw93cngpt5f7bg5s3hm0000gn/T/ipykernel_56489/3660601404.py:4: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n","  train_metadata = pd.read_csv(Config.BASE_PATH + Config.TRAIN_METADATA_PATH)\n"]}],"source":["train_hdf5 = h5py.File(Config.BASE_PATH + Config.TRAIN_IMAGE_PATH, 'r')\n","test_hdf5 = h5py.File(Config.BASE_PATH + Config.TEST_IMAGE_PATH, 'r')\n","\n","train_metadata = pd.read_csv(Config.BASE_PATH + Config.TRAIN_METADATA_PATH)\n","test_metadata = pd.read_csv(Config.BASE_PATH + Config.TEST_METADATA_PATH)\n","\n","# Add features\n","train_metadata, new_num_cols, new_cat_cols = feature_engineering(train_metadata)\n","test_metadata, _, _ = feature_engineering(test_metadata)\n","\n","fnames = train_metadata[\"isic_id\"].tolist()\n","test_fnames = test_metadata[\"isic_id\"].tolist()\n","\n","train_target = train_metadata[\"target\"]\n","\n","split = StratifiedShuffleSplit(n_splits=1, test_size=Config.VALIDATION_SPLIT, random_state=Config.RANDOM_STATE)\n","for train_index, val_index in split.split(train_metadata, train_target):\n","    val_fnames = itemgetter(*val_index)(fnames)\n","    train_fnames = itemgetter(*train_index)(fnames)\n","    X_metadata_train, X_metadata_val = train_metadata.iloc[train_index], train_metadata.iloc[val_index]\n","    y_train, y_val = train_target.iloc[train_index], train_target.iloc[val_index]"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:08:45.809867Z","iopub.status.busy":"2024-08-02T18:08:45.809462Z","iopub.status.idle":"2024-08-02T18:08:49.958505Z","shell.execute_reply":"2024-08-02T18:08:49.957520Z","shell.execute_reply.started":"2024-08-02T18:08:45.809831Z"},"trusted":true},"outputs":[],"source":["only_train_cols = [\"target\", \"lesion_id\", \"iddx_full\", \"iddx_1\", \"iddx_2\", \"iddx_3\", \"iddx_4\", \"iddx_5\", \"mel_mitotic_index\", \"mel_thick_mm\", \"tbp_lv_dnn_lesion_confidence\"]\n","unuseful_cols = [\"image_type\", \"patient_id\"]\n","removable_cols = only_train_cols + unuseful_cols + [\"isic_id\"]\n","\n","numeric_features = X_metadata_train.select_dtypes(include=['float64', 'int64']).columns.difference(removable_cols)\n","cat_features = X_metadata_train.select_dtypes(include=['object']).columns.difference(removable_cols)\n","\n","numeric_pipeline = Pipeline([\n","    ('impute', SimpleImputer(strategy='mean')),\n","    ('scale', StandardScaler())\n","])\n","\n","cat_pipeline = Pipeline([\n","    ('impute', SimpleImputer(strategy='most_frequent')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n","])\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_pipeline, numeric_features),\n","        ('cat', cat_pipeline, cat_features)\n","    ])\n","\n","metadata_preprocessing_pipeline = Pipeline([\n","    ('preprocessor', preprocessor)\n","])\n","\n","X_train_metadata_preprocessed = metadata_preprocessing_pipeline.fit_transform(X_metadata_train)\n","X_val_metadata_preprocessed = metadata_preprocessing_pipeline.transform(X_metadata_val)\n","X_test_metadata_preprocessed = metadata_preprocessing_pipeline.transform(test_metadata)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:08:49.960366Z","iopub.status.busy":"2024-08-02T18:08:49.960069Z","iopub.status.idle":"2024-08-02T18:08:50.367555Z","shell.execute_reply":"2024-08-02T18:08:50.366582Z","shell.execute_reply.started":"2024-08-02T18:08:49.960341Z"},"trusted":true},"outputs":[],"source":["train_transforms = A.Compose([\n","        A.RandomRotate90(p=0.5),\n","        A.Flip(p=0.5),\n","        A.ShiftScaleRotate(shift_limit=0.1, \n","                           scale_limit=0.15, \n","                           rotate_limit=60, \n","                           p=0.5),\n","        A.HueSaturationValue(\n","                hue_shift_limit=0.2, \n","                sat_shift_limit=0.2, \n","                val_shift_limit=0.2, \n","                p=0.5\n","            ),\n","        A.RandomBrightnessContrast(\n","                brightness_limit=(-0.1,0.1), \n","                contrast_limit=(-0.1, 0.1), \n","                p=0.5\n","            ),\n","        ], p=1.)\n","\n","def create_image_dataset(fnames, targets, hdf5):\n","    target_ds = tf.data.Dataset.from_tensor_slices(targets)\n","    \n","    def load_image(id):\n","        image = Image.open(io.BytesIO(np.array(hdf5[id.numpy()])))\n","        image = np.array(image.resize(Config.IMAGE_SIZE))\n","        image = (image - image.min()) / (image.max() - image.min())\n","        return image\n","\n","    # It doesn't work without this in Kaggle\n","    def set_shapes(image):\n","        image.set_shape([*Config.IMAGE_SIZE, 3])\n","        return image\n","\n","    # Create a dataset for images\n","    image_ds = tf.data.Dataset.from_tensor_slices(tf.constant(fnames))\n","    image_ds = image_ds.map(lambda x: tf.py_function(load_image, [x], tf.float32))\n","    image_ds = image_ds.map(set_shapes)\n","    solo_image_ds = tf.data.Dataset.zip((image_ds, target_ds))\n","\n","    return solo_image_ds\n","\n","train_solo_image_ds = create_image_dataset(train_fnames, y_train, train_hdf5)\n","val_solo_image_ds = create_image_dataset(val_fnames, y_val, train_hdf5)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:08:50.369371Z","iopub.status.busy":"2024-08-02T18:08:50.368765Z","iopub.status.idle":"2024-08-02T18:08:50.558085Z","shell.execute_reply":"2024-08-02T18:08:50.557152Z","shell.execute_reply.started":"2024-08-02T18:08:50.369341Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total train samples: 56079\n","Positive train samples: 279\n","Negative train samples: 55800\n","Total val samples: 11055\n","Positive val samples: 55\n","Negative val samples: 11000\n"]}],"source":["def augment_image(image, label):\n","    def apply_augmentation(img):\n","        img = img.numpy()\n","        img = train_transforms(image=img)['image']\n","        return img\n","\n","    augmented_image = tf.py_function(apply_augmentation, [image], tf.float32)\n","    augmented_image.set_shape(image.shape)\n","    return augmented_image, label\n","\n","# Apply the augmentation to the dataset\n","train_solo_image_augmented_ds = train_solo_image_ds.map(augment_image).batch(Config.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"markdown","metadata":{},"source":["# Auxiliary functions and classes"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:08:50.560159Z","iopub.status.busy":"2024-08-02T18:08:50.559464Z","iopub.status.idle":"2024-08-02T18:08:50.568633Z","shell.execute_reply":"2024-08-02T18:08:50.567750Z","shell.execute_reply.started":"2024-08-02T18:08:50.560124Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc, roc_auc_score\n","\n","def pauc_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n","    v_gt = abs(y_true - 1)\n","    v_pred = 1.0 - y_pred\n","    min_tpr = 0.80\n","    max_fpr = 1 - min_tpr\n","    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n","    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n","    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n","    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n","    \n","    return partial_auc\n","\n","class PAUCCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, validation_data):\n","        super(PAUCCallback, self).__init__()\n","        self.validation_data = validation_data\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        # Get predictions for validation data\n","        val_pred = self.model.predict(self.validation_data, verbose=0)\n","        \n","        # Extract true labels from validation data\n","        y_val = np.concatenate([y for x, y in self.validation_data], axis=0)\n","        \n","        # Calculate pAUC score\n","        pauc = pauc_score(y_val, val_pred)\n","        \n","        # Optionally, you can add the pAUC score to the logs\n","        logs['val_pauc'] = pauc"]},{"cell_type":"markdown","metadata":{},"source":["# Image Module"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T15:45:13.450490Z","iopub.status.busy":"2024-08-02T15:45:13.450124Z","iopub.status.idle":"2024-08-02T15:45:16.596330Z","shell.execute_reply":"2024-08-02T15:45:16.595538Z","shell.execute_reply.started":"2024-08-02T15:45:13.450461Z"},"trusted":true},"outputs":[],"source":["efficientNet = EfficientNetV2B0(weights='imagenet', pooling='avg', include_top=False)\n","\n","image_input = tf.keras.Input(shape=(*Config.IMAGE_SIZE, 3))\n","x = efficientNet(image_input)\n","x = Dense(512, kernel_initializer='he_normal')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(128, kernel_initializer='he_normal')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.3)(x)\n","x = Dense(1, activation='sigmoid')(x)\n","image_model = tf.keras.Model(inputs=image_input, outputs=x)"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T15:45:16.598071Z","iopub.status.busy":"2024-08-02T15:45:16.597779Z","iopub.status.idle":"2024-08-02T16:02:13.867943Z","shell.execute_reply":"2024-08-02T16:02:13.866911Z","shell.execute_reply.started":"2024-08-02T15:45:16.598048Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - loss: 0.3760\n","Epoch 1: saving model to models/image_model_epoch_01_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 364ms/step - loss: 0.3756 - val_loss: 0.0962 - val_pauc: 0.0594 - learning_rate: 5.0000e-04\n","Epoch 2/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0941\n","Epoch 2: saving model to models/image_model_epoch_02_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 189ms/step - loss: 0.0941 - val_loss: 0.5474 - val_pauc: 0.0741 - learning_rate: 2.5000e-04\n","Epoch 3/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0762\n","Epoch 3: saving model to models/image_model_epoch_03_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 188ms/step - loss: 0.0762 - val_loss: 0.0743 - val_pauc: 0.1143 - learning_rate: 1.2500e-04\n","Epoch 4/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0717\n","Epoch 4: saving model to models/image_model_epoch_04_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 186ms/step - loss: 0.0717 - val_loss: 0.0710 - val_pauc: 0.1087 - learning_rate: 6.2500e-05\n","Epoch 5/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0700\n","Epoch 5: saving model to models/image_model_epoch_05_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 186ms/step - loss: 0.0700 - val_loss: 0.0676 - val_pauc: 0.1291 - learning_rate: 3.1250e-05\n","Epoch 6/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0667\n","Epoch 6: saving model to models/image_model_epoch_06_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 187ms/step - loss: 0.0667 - val_loss: 0.0783 - val_pauc: 0.1344 - learning_rate: 1.5625e-05\n","Epoch 7/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0662\n","Epoch 7: saving model to models/image_model_epoch_07_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 198ms/step - loss: 0.0662 - val_loss: 0.0698 - val_pauc: 0.1343 - learning_rate: 7.8125e-06\n","Epoch 8/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0687\n","Epoch 8: saving model to models/image_model_epoch_08_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 187ms/step - loss: 0.0687 - val_loss: 0.0728 - val_pauc: 0.1304 - learning_rate: 3.9063e-06\n","Epoch 9/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0630\n","Epoch 9: saving model to models/image_model_epoch_09_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 196ms/step - loss: 0.0630 - val_loss: 0.0687 - val_pauc: 0.1317 - learning_rate: 1.9531e-06\n","Epoch 10/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0676\n","Epoch 10: saving model to models/image_model_epoch_10_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 187ms/step - loss: 0.0676 - val_loss: 0.0684 - val_pauc: 0.1304 - learning_rate: 9.7656e-07\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x7f4fc1265780>"]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["# Create a custom learning rate schedule\n","def lr_schedule(epoch, lr):\n","    return lr * 0.5\n","\n","# Create the ReduceLROnPlateau callback\n","reduce_lr = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n","\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","    filepath='models/image_model_epoch_{epoch:02d}_unfreezed.keras',\n","    save_freq='epoch',\n","    save_best_only=False,\n","    save_weights_only=False,\n","    verbose=1\n",")\n","\n","callbacks = [model_checkpoint, reduce_lr]\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","image_model.compile(optimizer=optimizer, loss='binary_crossentropy')\n","\n","image_model.fit(\n","    train_solo_image_augmented_ds,\n","    epochs=7,\n","    callbacks=callbacks,\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:30:12.692138Z","iopub.status.busy":"2024-08-02T18:30:12.691853Z","iopub.status.idle":"2024-08-02T18:34:35.548584Z","shell.execute_reply":"2024-08-02T18:34:35.547545Z","shell.execute_reply.started":"2024-08-02T18:30:12.692113Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 262ms/step\n","\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 380ms/step\n","Validation pAUC score with TTA: 0.1340\n"]}],"source":["tta_transforms = [\n","    A.RandomRotate90(p=1.0),\n","    A.Flip(p=1.0),\n","    A.ShiftScaleRotate(shift_limit=0.1, \n","                        scale_limit=0.15, \n","                        rotate_limit=60, \n","                        p=1.0),\n","    A.HueSaturationValue(\n","            hue_shift_limit=0.2, \n","            sat_shift_limit=0.2, \n","            val_shift_limit=0.2, \n","            p=1.0\n","        ),\n","    A.RandomBrightnessContrast(\n","            brightness_limit=(-0.1,0.1), \n","            contrast_limit=(-0.1, 0.1), \n","            p=1.0\n","        )\n","]\n","\n","def apply_transformation(image, transformation):\n","    def apply_augmentation(img):\n","        img = img.numpy()\n","        img = transformation(image=img)['image']\n","        return img\n","\n","    augmented_image = tf.py_function(apply_augmentation, [image], tf.float32)\n","    augmented_image.set_shape(image.shape)\n","    return augmented_image\n","\n","val_tta_preds = []\n","n = 450\n","\n","non_transformed_preds = image_model.predict(val_solo_image_ds.batch(128).prefetch(tf.data.AUTOTUNE).take(n), verbose=1)\n","val_tta_preds.append(non_transformed_preds.flatten())\n","\n","for transform in tta_transforms:\n","    augmented_ds = val_solo_image_ds.map(lambda x, y: (apply_transformation(x, transform), y)).batch(128).prefetch(tf.data.AUTOTUNE).take(n)\n","    preds = image_model.predict(augmented_ds, verbose=1)\n","    val_tta_preds.append(preds.flatten())\n","\n","# Average the predictions\n","val_tta_preds_mean = np.mean(val_tta_preds, axis=0)\n","val_tta_pauc = pauc_score(y_val[:128*n], val_tta_preds_mean)\n","print(f\"Validation pAUC score with TTA: {val_tta_pauc:.4f}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:42:18.691689Z","iopub.status.busy":"2024-08-02T18:42:18.691308Z","iopub.status.idle":"2024-08-02T18:42:18.711373Z","shell.execute_reply":"2024-08-02T18:42:18.710362Z","shell.execute_reply.started":"2024-08-02T18:42:18.691657Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.137797375699295"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["select = [0]\n","x = np.mean(np.array(val_tta_preds)[select], axis=0)\n","pauc_score(y_val[:128*n], x)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":9094797,"sourceId":63056,"sourceType":"competition"},{"datasetId":5481865,"sourceId":9085429,"sourceType":"datasetVersion"},{"datasetId":5486202,"sourceId":9091430,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
