{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:08:33.526006Z","iopub.status.busy":"2024-08-02T18:08:33.525629Z","iopub.status.idle":"2024-08-02T18:08:37.347298Z","shell.execute_reply":"2024-08-02T18:08:37.346443Z","shell.execute_reply.started":"2024-08-02T18:08:33.525977Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dense, BatchNormalization, Activation, Dropout\n","from tensorflow.keras.applications import EfficientNetV2B0\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import h5py\n","import io\n","from PIL import Image\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from operator import itemgetter\n","import os\n","import albumentations as A\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:08:37.349942Z","iopub.status.busy":"2024-08-02T18:08:37.348996Z","iopub.status.idle":"2024-08-02T18:08:37.356191Z","shell.execute_reply":"2024-08-02T18:08:37.355280Z","shell.execute_reply.started":"2024-08-02T18:08:37.349904Z"},"trusted":true},"outputs":[],"source":["def is_kaggle():\n","    return os.path.exists('/kaggle')\n","\n","class Config:\n","    BASE_PATH = '/kaggle/input/isic-2024-challenge/' if is_kaggle() else 'isic-2024-challenge/'\n","    TRAIN_IMAGE_PATH = 'train-image.hdf5'\n","    TRAIN_METADATA_PATH = 'train-metadata.csv'\n","    TEST_IMAGE_PATH = 'test-image.hdf5'\n","    TEST_METADATA_PATH = 'test-metadata.csv'\n","    \n","    # Data processing\n","    IMAGE_SIZE = (224, 224)\n","    VALIDATION_SPLIT = 0.15\n","    RANDOM_STATE = 42\n","    \n","    BATCH_SIZE = 64"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:08:37.382335Z","iopub.status.busy":"2024-08-02T18:08:37.382064Z","iopub.status.idle":"2024-08-02T18:08:45.808113Z","shell.execute_reply":"2024-08-02T18:08:45.807021Z","shell.execute_reply.started":"2024-08-02T18:08:37.382312Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/3660601404.py:4: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n","  train_metadata = pd.read_csv(Config.BASE_PATH + Config.TRAIN_METADATA_PATH)\n"]}],"source":["train_hdf5 = h5py.File(Config.BASE_PATH + Config.TRAIN_IMAGE_PATH, 'r')\n","test_hdf5 = h5py.File(Config.BASE_PATH + Config.TEST_IMAGE_PATH, 'r')\n","\n","train_metadata = pd.read_csv(Config.BASE_PATH + Config.TRAIN_METADATA_PATH)\n","test_metadata = pd.read_csv(Config.BASE_PATH + Config.TEST_METADATA_PATH)\n","\n","fnames = train_metadata[\"isic_id\"].tolist()\n","test_fnames = test_metadata[\"isic_id\"].tolist()\n","\n","train_target = train_metadata[\"target\"]\n","\n","split = StratifiedShuffleSplit(n_splits=1, test_size=Config.VALIDATION_SPLIT, random_state=Config.RANDOM_STATE)\n","for train_index, val_index in split.split(train_metadata, train_target):\n","    val_fnames = itemgetter(*val_index)(fnames)\n","    train_fnames = itemgetter(*train_index)(fnames)\n","    y_train, y_val = train_target.iloc[train_index], train_target.iloc[val_index]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:08:49.960366Z","iopub.status.busy":"2024-08-02T18:08:49.960069Z","iopub.status.idle":"2024-08-02T18:08:50.367555Z","shell.execute_reply":"2024-08-02T18:08:50.366582Z","shell.execute_reply.started":"2024-08-02T18:08:49.960341Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n","import albumentations as A\n","\n","train_transforms = A.Compose([\n","        A.RandomRotate90(p=0.5),\n","        A.Flip(p=0.5),\n","        A.ShiftScaleRotate(shift_limit=0.1, \n","                           scale_limit=0.15, \n","                           rotate_limit=60, \n","                           p=0.5),\n","        A.HueSaturationValue(\n","                hue_shift_limit=0.2, \n","                sat_shift_limit=0.2, \n","                val_shift_limit=0.2, \n","                p=0.5\n","            ),\n","        A.RandomBrightnessContrast(\n","                brightness_limit=(-0.1,0.1), \n","                contrast_limit=(-0.1, 0.1), \n","                p=0.5\n","            ),\n","        ], p=1.)\n","\n","def create_image_dataset(fnames, targets, hdf5):\n","    target_ds = tf.data.Dataset.from_tensor_slices(targets)\n","    \n","    def load_image(id):\n","        image = Image.open(io.BytesIO(np.array(hdf5[id.numpy()])))\n","        image = np.array(image.resize(Config.IMAGE_SIZE))\n","        image = (image - image.min()) / (image.max() - image.min())\n","        return image\n","\n","    # It doesn't work without this in Kaggle\n","    def set_shapes(image):\n","        image.set_shape([*Config.IMAGE_SIZE, 3])\n","        return image\n","\n","    # Create a dataset for images\n","    image_ds = tf.data.Dataset.from_tensor_slices(tf.constant(fnames))\n","    image_ds = image_ds.map(lambda x: tf.py_function(load_image, [x], tf.float32))\n","    image_ds = image_ds.map(set_shapes)\n","    solo_image_ds = tf.data.Dataset.zip((image_ds, target_ds))\n","\n","    return solo_image_ds\n","\n","train_solo_image_ds = create_image_dataset(train_fnames, y_train, train_hdf5)\n","val_solo_image_ds = create_image_dataset(val_fnames, y_val, train_hdf5)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:08:50.369371Z","iopub.status.busy":"2024-08-02T18:08:50.368765Z","iopub.status.idle":"2024-08-02T18:08:50.558085Z","shell.execute_reply":"2024-08-02T18:08:50.557152Z","shell.execute_reply.started":"2024-08-02T18:08:50.369341Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total train samples: 56079\n","Positive train samples: 279\n","Negative train samples: 55800\n","Total val samples: 11055\n","Positive val samples: 55\n","Negative val samples: 11000\n"]}],"source":["# Create a reduced set of training and validation for the CNN\n","y_train_reset = y_train.reset_index(drop=True)\n","\n","# Get the positive instances\n","positive_indices = np.where(y_train_reset == 1)[0]\n","train_limit = positive_indices.shape[0]//6\n","positive_val_indices = positive_indices[:train_limit]\n","positive_train_indices = positive_indices[train_limit:]\n","positive_val_count = len(positive_val_indices)\n","positive_train_count = len(positive_train_indices)\n","\n","negative_ratio = 200\n","negative_indices = np.where(y_train_reset == 0)[0]\n","negative_train_count = negative_ratio * positive_train_count\n","negative_val_count = negative_ratio * positive_val_count\n","negative_train_indices = np.random.choice(negative_indices, size=negative_train_count, replace=False)\n","negative_val_indices = np.random.choice(negative_indices, size=negative_val_count, replace=False)\n","\n","# Combine positive and selected negative indices\n","selected_train_indices = np.concatenate([positive_train_indices, negative_train_indices])\n","selected_val_indices = np.concatenate([positive_val_indices, negative_val_indices])\n","\n","# Shuffle the indices\n","np.random.shuffle(selected_train_indices)\n","np.random.shuffle(selected_val_indices)\n","\n","# Create the reduced datasets\n","train_fnames_reduced = [train_fnames[i] for i in selected_train_indices]\n","y_train_reduced = y_train_reset[selected_train_indices]\n","val_fnames_reduced = [train_fnames[i] for i in selected_val_indices]\n","y_val_reduced = y_train_reset[selected_val_indices]\n","\n","print(f\"Total train samples: {len(selected_train_indices)}\")\n","print(f\"Positive train samples: {positive_train_count}\")\n","print(f\"Negative train samples: {negative_train_count}\")\n","print(f\"Total val samples: {len(selected_val_indices)}\")\n","print(f\"Positive val samples: {positive_val_count}\")\n","print(f\"Negative val samples: {negative_val_count}\")\n","\n","# Now create the dataset with the reduced and balanced data\n","train_solo_image_reduced_ds = create_image_dataset(train_fnames_reduced, y_train_reduced, train_hdf5)\n","val_solo_image_reduced_ds = create_image_dataset(val_fnames_reduced, y_val_reduced, train_hdf5)\n","\n","def augment_image(image, label):\n","    def apply_augmentation(img):\n","        img = img.numpy()\n","        img = train_transforms(image=img)['image']\n","        return img\n","\n","    augmented_image = tf.py_function(apply_augmentation, [image], tf.float32)\n","    augmented_image.set_shape(image.shape)\n","    return augmented_image, label\n","\n","# Apply the augmentation to the dataset\n","train_solo_image_reduced_ds = train_solo_image_reduced_ds.map(augment_image).batch(Config.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","val_solo_image_reduced_ds = val_solo_image_reduced_ds.batch(Config.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"markdown","metadata":{},"source":["# Auxiliary functions and classes"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:08:50.560159Z","iopub.status.busy":"2024-08-02T18:08:50.559464Z","iopub.status.idle":"2024-08-02T18:08:50.568633Z","shell.execute_reply":"2024-08-02T18:08:50.567750Z","shell.execute_reply.started":"2024-08-02T18:08:50.560124Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc, roc_auc_score\n","\n","def pauc_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n","    v_gt = abs(y_true - 1)\n","    v_pred = 1.0 - y_pred\n","    min_tpr = 0.80\n","    max_fpr = 1 - min_tpr\n","    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n","    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n","    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n","    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n","    \n","    return partial_auc\n","\n","class PAUCCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, validation_data):\n","        super(PAUCCallback, self).__init__()\n","        self.validation_data = validation_data\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        # Get predictions for validation data\n","        val_pred = self.model.predict(self.validation_data, verbose=0)\n","        \n","        # Extract true labels from validation data\n","        y_val = np.concatenate([y for x, y in self.validation_data], axis=0)\n","        \n","        # Calculate pAUC score\n","        pauc = pauc_score(y_val, val_pred)\n","        \n","        # Optionally, you can add the pAUC score to the logs\n","        logs['val_pauc'] = pauc"]},{"cell_type":"markdown","metadata":{},"source":["# Image Module"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T15:45:13.450490Z","iopub.status.busy":"2024-08-02T15:45:13.450124Z","iopub.status.idle":"2024-08-02T15:45:16.596330Z","shell.execute_reply":"2024-08-02T15:45:16.595538Z","shell.execute_reply.started":"2024-08-02T15:45:13.450461Z"},"trusted":true},"outputs":[],"source":["efficientNet = EfficientNetV2B0(weights='imagenet', pooling='avg', include_top=False)\n","\n","image_input = tf.keras.Input(shape=(*Config.IMAGE_SIZE, 3))\n","x = efficientNet(image_input)\n","x = Dense(512, kernel_initializer='he_normal')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.4)(x)\n","x = Dense(128, kernel_initializer='he_normal')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.2)(x)\n","x = Dense(1, activation='sigmoid')(x)\n","image_model = tf.keras.Model(inputs=image_input, outputs=x)"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T15:45:16.598071Z","iopub.status.busy":"2024-08-02T15:45:16.597779Z","iopub.status.idle":"2024-08-02T16:02:13.867943Z","shell.execute_reply":"2024-08-02T16:02:13.866911Z","shell.execute_reply.started":"2024-08-02T15:45:16.598048Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - loss: 0.3760\n","Epoch 1: saving model to models/image_model_epoch_01_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 364ms/step - loss: 0.3756 - val_loss: 0.0962 - val_pauc: 0.0594 - learning_rate: 5.0000e-04\n","Epoch 2/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0941\n","Epoch 2: saving model to models/image_model_epoch_02_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 189ms/step - loss: 0.0941 - val_loss: 0.5474 - val_pauc: 0.0741 - learning_rate: 2.5000e-04\n","Epoch 3/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0762\n","Epoch 3: saving model to models/image_model_epoch_03_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 188ms/step - loss: 0.0762 - val_loss: 0.0743 - val_pauc: 0.1143 - learning_rate: 1.2500e-04\n","Epoch 4/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0717\n","Epoch 4: saving model to models/image_model_epoch_04_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 186ms/step - loss: 0.0717 - val_loss: 0.0710 - val_pauc: 0.1087 - learning_rate: 6.2500e-05\n","Epoch 5/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0700\n","Epoch 5: saving model to models/image_model_epoch_05_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 186ms/step - loss: 0.0700 - val_loss: 0.0676 - val_pauc: 0.1291 - learning_rate: 3.1250e-05\n","Epoch 6/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0667\n","Epoch 6: saving model to models/image_model_epoch_06_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 187ms/step - loss: 0.0667 - val_loss: 0.0783 - val_pauc: 0.1344 - learning_rate: 1.5625e-05\n","Epoch 7/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0662\n","Epoch 7: saving model to models/image_model_epoch_07_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 198ms/step - loss: 0.0662 - val_loss: 0.0698 - val_pauc: 0.1343 - learning_rate: 7.8125e-06\n","Epoch 8/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0687\n","Epoch 8: saving model to models/image_model_epoch_08_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 187ms/step - loss: 0.0687 - val_loss: 0.0728 - val_pauc: 0.1304 - learning_rate: 3.9063e-06\n","Epoch 9/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0630\n","Epoch 9: saving model to models/image_model_epoch_09_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 196ms/step - loss: 0.0630 - val_loss: 0.0687 - val_pauc: 0.1317 - learning_rate: 1.9531e-06\n","Epoch 10/10\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0676\n","Epoch 10: saving model to models/image_model_epoch_10_unfreezed.keras\n","\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 187ms/step - loss: 0.0676 - val_loss: 0.0684 - val_pauc: 0.1304 - learning_rate: 9.7656e-07\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x7f4fc1265780>"]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["from tensorflow.keras.callbacks import ReduceLROnPlateau\n","\n","# Create a custom learning rate schedule\n","def lr_schedule(epoch, lr):\n","    return lr * 0.7\n","\n","reduce_lr = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n","\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","    filepath='models/image_model_epoch_{epoch:02d}_unfreezed.keras',\n","    save_freq='epoch',\n","    save_best_only=False,\n","    save_weights_only=False,\n","    verbose=1\n",")\n","pauc_callback = PAUCCallback(val_solo_image_reduced_ds)\n","\n","callbacks = [model_checkpoint, pauc_callback, reduce_lr]\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4) if is_kaggle() else tf.keras.optimizers.legacy.Adam(learning_rate=1e-4)\n","image_model.compile(optimizer=optimizer, loss='binary_crossentropy')\n","\n","image_model.fit(\n","    train_solo_image_reduced_ds,\n","    epochs=8,\n","    callbacks=callbacks,\n","    validation_data=val_solo_image_reduced_ds\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:30:05.567910Z","iopub.status.busy":"2024-08-02T18:30:05.567538Z","iopub.status.idle":"2024-08-02T18:30:12.689856Z","shell.execute_reply":"2024-08-02T18:30:12.688857Z","shell.execute_reply.started":"2024-08-02T18:30:05.567876Z"},"trusted":true},"outputs":[],"source":["epoch_model = 8\n","image_model = tf.keras.models.load_model(f\"/kaggle/input/mejores-modelos-isic-2024/models/image_model_epoch_{epoch_model:02d}_unfreezed.keras\", compile=False)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:30:12.692138Z","iopub.status.busy":"2024-08-02T18:30:12.691853Z","iopub.status.idle":"2024-08-02T18:34:35.548584Z","shell.execute_reply":"2024-08-02T18:34:35.547545Z","shell.execute_reply.started":"2024-08-02T18:30:12.692113Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 262ms/step\n","\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 380ms/step\n","Validation pAUC score with TTA: 0.1340\n"]}],"source":["tta_transforms = [\n","    A.RandomRotate90(p=1.0),\n","    A.Flip(p=1.0),\n","    A.ShiftScaleRotate(shift_limit=0.1, \n","                        scale_limit=0.15, \n","                        rotate_limit=60, \n","                        p=1.0),\n","    A.HueSaturationValue(\n","            hue_shift_limit=0.2, \n","            sat_shift_limit=0.2, \n","            val_shift_limit=0.2, \n","            p=1.0\n","        ),\n","    A.RandomBrightnessContrast(\n","            brightness_limit=(-0.1,0.1), \n","            contrast_limit=(-0.1, 0.1), \n","            p=1.0\n","        )\n","]\n","\n","def apply_transformation(image, transformation):\n","    def apply_augmentation(img):\n","        img = img.numpy()\n","        img = transformation(image=img)['image']\n","        return img\n","\n","    augmented_image = tf.py_function(apply_augmentation, [image], tf.float32)\n","    augmented_image.set_shape(image.shape)\n","    return augmented_image\n","\n","val_tta_preds = []\n","n = 400\n","\n","non_transformed_preds = image_model.predict(val_solo_image_ds.batch(128).prefetch(tf.data.AUTOTUNE).take(n), verbose=1)\n","val_tta_preds.append(non_transformed_preds.flatten())\n","\n","for transform in tta_transforms:\n","    augmented_ds = val_solo_image_ds.map(lambda x, y: (apply_transformation(x, transform), y)).batch(128).prefetch(tf.data.AUTOTUNE).take(n)\n","    preds = image_model.predict(augmented_ds, verbose=1)\n","    val_tta_preds.append(preds.flatten())\n","\n","# Average the predictions\n","val_tta_preds_mean = np.mean(val_tta_preds, axis=0)\n","val_tta_pauc = pauc_score(y_val[:128*n], val_tta_preds_mean)\n","print(f\"Validation pAUC score with TTA: {val_tta_pauc:.4f}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T18:42:18.691689Z","iopub.status.busy":"2024-08-02T18:42:18.691308Z","iopub.status.idle":"2024-08-02T18:42:18.711373Z","shell.execute_reply":"2024-08-02T18:42:18.710362Z","shell.execute_reply.started":"2024-08-02T18:42:18.691657Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.137797375699295"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["select = [0]\n","x = np.mean(np.array(val_tta_preds)[select], axis=0)\n","pauc_score(y_val[:128*n], x)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":9094797,"sourceId":63056,"sourceType":"competition"},{"datasetId":5481865,"sourceId":9085429,"sourceType":"datasetVersion"},{"datasetId":5486202,"sourceId":9091430,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
